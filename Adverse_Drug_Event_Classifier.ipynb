{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíä Adverse Drug Event Severity Classifier\n",
    "\n",
    "**Author:** Jason Finkle  \n",
    "**Project:** Healthcare NLP / Pharmacovigilance Classification  \n",
    "\n",
    "This project predicts the severity of adverse drug events using data from the FDA Adverse Event Reporting System (FAERS). By analyzing drug characteristics, patient demographics, and MedDRA-coded reaction terms, we build machine learning models to classify whether an adverse event resulted in serious outcomes (hospitalization, disability, life-threatening conditions, or death).\n",
    "\n",
    "**Business Value:** Pharmaceutical companies spend millions annually on pharmacovigilance. Automated severity classification can help:\n",
    "- Prioritize safety reports for medical review\n",
    "- Identify high-risk drug-event combinations\n",
    "- Support regulatory compliance (15-day serious AE reporting requirement)\n",
    "- Enable early signal detection for drug safety\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             classification_report, confusion_matrix, roc_curve, auc,\n",
    "                             roc_auc_score)\n",
    "\n",
    "# Model Interpretability\n",
    "import shap\n",
    "\n",
    "# Scipy for sparse matrix operations\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Set random seed\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Define color palette\n",
    "COLORS = {\n",
    "    'primary': '#2E86AB',\n",
    "    'secondary': '#A23B72',\n",
    "    'accent': '#F18F01',\n",
    "    'success': '#28A745',\n",
    "    'danger': '#DC3545',\n",
    "    'warning': '#FFC107',\n",
    "    'dark': '#343A40',\n",
    "    'purple': '#6F42C1',\n",
    "    'teal': '#20C997'\n",
    "}\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully\")\n",
    "print(\"   - NLP: TF-IDF, CountVectorizer\")\n",
    "print(\"   - ML: Logistic Regression, Random Forest, Gradient Boosting, Naive Bayes\")\n",
    "print(\"   - Interpretability: SHAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection from FDA FAERS API\n",
    "\n",
    "We'll use the openFDA API to fetch adverse event reports. The API provides:\n",
    "- **Drug information**: Brand names, generic names, routes of administration\n",
    "- **Patient demographics**: Age, sex, weight\n",
    "- **Reaction terms**: MedDRA-coded adverse event descriptions\n",
    "- **Seriousness indicators**: Death, hospitalization, life-threatening, disability\n",
    "\n",
    "Our target variable will be **severity level** based on seriousness indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_faers_data(search_term=None, max_records=10000, limit_per_call=100):\n",
    "    \"\"\"\n",
    "    Fetch adverse event reports from openFDA FAERS API\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    search_term : str, optional\n",
    "        Drug name or condition to search for\n",
    "    max_records : int\n",
    "        Maximum number of records to fetch\n",
    "    limit_per_call : int\n",
    "        Records per API call (max 100)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : List of adverse event records\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = \"https://api.fda.gov/drug/event.json\"\n",
    "    all_records = []\n",
    "    skip = 0\n",
    "    \n",
    "    print(f\"üì• Fetching FAERS data...\")\n",
    "    if search_term:\n",
    "        print(f\"   Search term: {search_term}\")\n",
    "    \n",
    "    while len(all_records) < max_records:\n",
    "        params = {\n",
    "            \"limit\": min(limit_per_call, max_records - len(all_records)),\n",
    "            \"skip\": skip\n",
    "        }\n",
    "        \n",
    "        # Add search term if provided\n",
    "        if search_term:\n",
    "            params[\"search\"] = search_term\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, params=params, timeout=30)\n",
    "            \n",
    "            if response.status_code == 404:\n",
    "                print(f\"   ‚ö†Ô∏è No more records found\")\n",
    "                break\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            results = data.get(\"results\", [])\n",
    "            if not results:\n",
    "                break\n",
    "            \n",
    "            all_records.extend(results)\n",
    "            skip += limit_per_call\n",
    "            \n",
    "            # Progress update\n",
    "            if len(all_records) % 1000 == 0:\n",
    "                print(f\"   Retrieved {len(all_records):,} records...\")\n",
    "            \n",
    "            # Rate limiting (40 requests/min without API key)\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"   ‚ö†Ô∏è API error: {e}\")\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "    \n",
    "    print(f\"   ‚úÖ Retrieved {len(all_records):,} adverse event records\")\n",
    "    return all_records\n",
    "\n",
    "\n",
    "# Check if data already exists\n",
    "DATA_FILE = \"data/faers_adverse_events.csv\"\n",
    "\n",
    "if os.path.exists(DATA_FILE):\n",
    "    print(f\"üìÇ Loading cached data from {DATA_FILE}\")\n",
    "    df_raw = pd.read_csv(DATA_FILE)\n",
    "    print(f\"   Loaded {len(df_raw):,} records\")\n",
    "else:\n",
    "    print(\"üåê Fetching data from openFDA API...\")\n",
    "    print(\"   (This may take 10-15 minutes)\\n\")\n",
    "    \n",
    "    # Fetch diverse set of adverse events\n",
    "    # We'll fetch recent serious events to get a good mix\n",
    "    all_records = fetch_faers_data(max_records=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_event_features(record):\n",
    "    \"\"\"\n",
    "    Extract relevant features from a FAERS record\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    record : dict\n",
    "        Raw record from API\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Extracted features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Report metadata\n",
    "    safety_report_id = record.get(\"safetyreportid\", \"\")\n",
    "    receive_date = record.get(\"receivedate\", \"\")\n",
    "    \n",
    "    # Seriousness indicators (our target)\n",
    "    serious = record.get(\"serious\", \"\")\n",
    "    seriousness_death = record.get(\"seriousnessdeath\", \"0\")\n",
    "    seriousness_hosp = record.get(\"seriousnesshospitalization\", \"0\")\n",
    "    seriousness_lifethreat = record.get(\"seriousnesslifethreatening\", \"0\")\n",
    "    seriousness_disable = record.get(\"seriousnessdisabling\", \"0\")\n",
    "    seriousness_congential = record.get(\"seriousnesscongenitalanomali\", \"0\")\n",
    "    seriousness_other = record.get(\"seriousnessother\", \"0\")\n",
    "    \n",
    "    # Patient info\n",
    "    patient = record.get(\"patient\", {})\n",
    "    patient_age = patient.get(\"patientonsetage\", \"\")\n",
    "    patient_age_unit = patient.get(\"patientonsetageunit\", \"\")\n",
    "    patient_sex = patient.get(\"patientsex\", \"\")\n",
    "    patient_weight = patient.get(\"patientweight\", \"\")\n",
    "    \n",
    "    # Drugs involved\n",
    "    drugs = patient.get(\"drug\", [])\n",
    "    drug_names = []\n",
    "    drug_indications = []\n",
    "    drug_routes = []\n",
    "    suspect_drugs = []\n",
    "    \n",
    "    for drug in drugs:\n",
    "        med_name = drug.get(\"medicinalproduct\", \"\")\n",
    "        if med_name:\n",
    "            drug_names.append(med_name.upper())\n",
    "        \n",
    "        # Get openfda standardized names\n",
    "        openfda = drug.get(\"openfda\", {})\n",
    "        generic_names = openfda.get(\"generic_name\", [])\n",
    "        brand_names = openfda.get(\"brand_name\", [])\n",
    "        drug_names.extend([n.upper() for n in generic_names])\n",
    "        drug_names.extend([n.upper() for n in brand_names])\n",
    "        \n",
    "        indication = drug.get(\"drugindication\", \"\")\n",
    "        if indication:\n",
    "            drug_indications.append(indication.upper())\n",
    "        \n",
    "        route = drug.get(\"drugadministrationroute\", \"\")\n",
    "        if route:\n",
    "            drug_routes.append(route)\n",
    "        \n",
    "        # Check if suspect drug\n",
    "        if drug.get(\"drugcharacterization\", \"\") == \"1\":\n",
    "            suspect_drugs.append(med_name.upper() if med_name else \"\")\n",
    "    \n",
    "    # Reactions (MedDRA terms) - this is our main text feature\n",
    "    reactions = patient.get(\"reaction\", [])\n",
    "    reaction_terms = []\n",
    "    reaction_outcomes = []\n",
    "    \n",
    "    for reaction in reactions:\n",
    "        term = reaction.get(\"reactionmeddrapt\", \"\")\n",
    "        if term:\n",
    "            reaction_terms.append(term.upper())\n",
    "        outcome = reaction.get(\"reactionoutcome\", \"\")\n",
    "        if outcome:\n",
    "            reaction_outcomes.append(outcome)\n",
    "    \n",
    "    # Reporter info\n",
    "    primary_source = record.get(\"primarysource\", {})\n",
    "    reporter_qualification = primary_source.get(\"qualification\", \"\")\n",
    "    reporter_country = record.get(\"occurcountry\", \"\")\n",
    "    \n",
    "    return {\n",
    "        'safety_report_id': safety_report_id,\n",
    "        'receive_date': receive_date,\n",
    "        'serious': serious,\n",
    "        'seriousness_death': seriousness_death,\n",
    "        'seriousness_hospitalization': seriousness_hosp,\n",
    "        'seriousness_lifethreatening': seriousness_lifethreat,\n",
    "        'seriousness_disabling': seriousness_disable,\n",
    "        'seriousness_congenital': seriousness_congential,\n",
    "        'seriousness_other': seriousness_other,\n",
    "        'patient_age': patient_age,\n",
    "        'patient_age_unit': patient_age_unit,\n",
    "        'patient_sex': patient_sex,\n",
    "        'patient_weight': patient_weight,\n",
    "        'drug_names': ' | '.join(list(set(drug_names))),\n",
    "        'drug_indications': ' | '.join(list(set(drug_indications))),\n",
    "        'drug_routes': ' | '.join(list(set(drug_routes))),\n",
    "        'suspect_drugs': ' | '.join(list(set(suspect_drugs))),\n",
    "        'num_drugs': len(drugs),\n",
    "        'num_suspect_drugs': len(suspect_drugs),\n",
    "        'reaction_terms': ' | '.join(reaction_terms),\n",
    "        'reaction_text': ' '.join(reaction_terms),  # For NLP\n",
    "        'num_reactions': len(reaction_terms),\n",
    "        'reaction_outcomes': ' | '.join(reaction_outcomes),\n",
    "        'reporter_qualification': reporter_qualification,\n",
    "        'reporter_country': reporter_country\n",
    "    }\n",
    "\n",
    "\n",
    "# Process records if not cached\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    print(\"\\nüîÑ Processing adverse event records...\")\n",
    "    \n",
    "    processed_records = []\n",
    "    for i, record in enumerate(all_records):\n",
    "        try:\n",
    "            features = extract_event_features(record)\n",
    "            processed_records.append(features)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        if (i + 1) % 2000 == 0:\n",
    "            print(f\"   Processed {i + 1:,} records...\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_raw = pd.DataFrame(processed_records)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df_raw.to_csv(DATA_FILE, index=False)\n",
    "    print(f\"\\n‚úÖ Saved {len(df_raw):,} records to {DATA_FILE}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset shape: {df_raw.shape}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working copy\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Convert seriousness columns to numeric\n",
    "seriousness_cols = ['seriousness_death', 'seriousness_hospitalization', \n",
    "                    'seriousness_lifethreatening', 'seriousness_disabling',\n",
    "                    'seriousness_congenital', 'seriousness_other']\n",
    "\n",
    "for col in seriousness_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Create severity target variable (hierarchical)\n",
    "# Level 4: Death (most severe)\n",
    "# Level 3: Life-threatening\n",
    "# Level 2: Hospitalization or Disabling\n",
    "# Level 1: Other serious\n",
    "# Level 0: Non-serious\n",
    "\n",
    "def assign_severity(row):\n",
    "    if row['seriousness_death'] == 1:\n",
    "        return 4  # Death\n",
    "    elif row['seriousness_lifethreatening'] == 1:\n",
    "        return 3  # Life-threatening\n",
    "    elif row['seriousness_hospitalization'] == 1 or row['seriousness_disabling'] == 1:\n",
    "        return 2  # Hospitalization/Disabling\n",
    "    elif row['seriousness_other'] == 1 or row['seriousness_congenital'] == 1:\n",
    "        return 1  # Other serious\n",
    "    else:\n",
    "        return 0  # Non-serious\n",
    "\n",
    "df['severity'] = df.apply(assign_severity, axis=1)\n",
    "\n",
    "# Create severity labels\n",
    "severity_labels = {\n",
    "    0: 'Non-Serious',\n",
    "    1: 'Other Serious',\n",
    "    2: 'Hospitalization/Disability',\n",
    "    3: 'Life-Threatening',\n",
    "    4: 'Death'\n",
    "}\n",
    "df['severity_label'] = df['severity'].map(severity_labels)\n",
    "\n",
    "# For binary classification (simpler, more balanced)\n",
    "# Severe (death, life-threatening, hospitalization) vs Non-severe\n",
    "df['is_severe'] = (df['severity'] >= 2).astype(int)\n",
    "\n",
    "print(\"üìä TARGET VARIABLE DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nSeverity Levels (Multi-class):\")\n",
    "print(df['severity_label'].value_counts().sort_index())\n",
    "print(f\"\\nBinary Classification:\")\n",
    "print(f\"   Severe (hospitalization/life-threatening/death): {df['is_severe'].sum():,} ({df['is_severe'].mean()*100:.1f}%)\")\n",
    "print(f\"   Non-severe: {(1-df['is_severe']).sum():,} ({(1-df['is_severe'].mean())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean patient demographics\n",
    "# Standardize age to years\n",
    "def convert_age_to_years(row):\n",
    "    age = pd.to_numeric(row['patient_age'], errors='coerce')\n",
    "    unit = str(row['patient_age_unit'])\n",
    "    \n",
    "    if pd.isna(age):\n",
    "        return np.nan\n",
    "    \n",
    "    # Unit codes: 800=decade, 801=year, 802=month, 803=week, 804=day, 805=hour\n",
    "    if unit == '800':\n",
    "        return age * 10\n",
    "    elif unit == '801':\n",
    "        return age\n",
    "    elif unit == '802':\n",
    "        return age / 12\n",
    "    elif unit == '803':\n",
    "        return age / 52\n",
    "    elif unit == '804':\n",
    "        return age / 365\n",
    "    elif unit == '805':\n",
    "        return age / (365 * 24)\n",
    "    else:\n",
    "        return age  # Assume years if unknown\n",
    "\n",
    "df['age_years'] = df.apply(convert_age_to_years, axis=1)\n",
    "\n",
    "# Filter reasonable ages (0-120)\n",
    "df.loc[df['age_years'] > 120, 'age_years'] = np.nan\n",
    "df.loc[df['age_years'] < 0, 'age_years'] = np.nan\n",
    "\n",
    "# Clean weight (convert to kg, filter outliers)\n",
    "df['weight_kg'] = pd.to_numeric(df['patient_weight'], errors='coerce')\n",
    "df.loc[df['weight_kg'] > 300, 'weight_kg'] = np.nan\n",
    "df.loc[df['weight_kg'] < 1, 'weight_kg'] = np.nan\n",
    "\n",
    "# Clean sex (1=Male, 2=Female, 0=Unknown)\n",
    "df['sex'] = pd.to_numeric(df['patient_sex'], errors='coerce').fillna(0).astype(int)\n",
    "sex_labels = {0: 'Unknown', 1: 'Male', 2: 'Female'}\n",
    "df['sex_label'] = df['sex'].map(sex_labels)\n",
    "\n",
    "# Reporter qualification\n",
    "# 1=Physician, 2=Pharmacist, 3=Other health professional, 4=Lawyer, 5=Consumer\n",
    "df['reporter_qual'] = pd.to_numeric(df['reporter_qualification'], errors='coerce').fillna(5).astype(int)\n",
    "df['is_health_professional'] = (df['reporter_qual'].isin([1, 2, 3])).astype(int)\n",
    "\n",
    "# Clean reaction text\n",
    "df['reaction_text'] = df['reaction_text'].fillna('').str.strip()\n",
    "\n",
    "# Filter out records with no reaction text\n",
    "df = df[df['reaction_text'].str.len() > 0].copy()\n",
    "\n",
    "print(\"‚úÖ Data cleaning complete\")\n",
    "print(f\"\\nCleaned dataset shape: {df.shape}\")\n",
    "print(f\"\\nPatient Age (years):\")\n",
    "print(df['age_years'].describe())\n",
    "print(f\"\\nSex distribution:\")\n",
    "print(df['sex_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Severity Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Multi-class severity\n",
    "ax1 = axes[0]\n",
    "severity_counts = df['severity_label'].value_counts().reindex(\n",
    "    ['Non-Serious', 'Other Serious', 'Hospitalization/Disability', 'Life-Threatening', 'Death']\n",
    ")\n",
    "colors_severity = [COLORS['success'], COLORS['accent'], COLORS['warning'], \n",
    "                   COLORS['secondary'], COLORS['danger']]\n",
    "\n",
    "bars = ax1.bar(range(len(severity_counts)), severity_counts.values, \n",
    "               color=colors_severity, edgecolor='white')\n",
    "ax1.set_xticks(range(len(severity_counts)))\n",
    "ax1.set_xticklabels(severity_counts.index, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Number of Reports')\n",
    "ax1.set_title('Adverse Event Severity Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "for bar, val in zip(bars, severity_counts.values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "             f'{val:,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Right: Binary classification\n",
    "ax2 = axes[1]\n",
    "binary_counts = df['is_severe'].value_counts()\n",
    "labels = ['Non-Severe', 'Severe']\n",
    "colors_binary = [COLORS['success'], COLORS['danger']]\n",
    "\n",
    "bars = ax2.bar(labels, [binary_counts.get(0, 0), binary_counts.get(1, 0)],\n",
    "               color=colors_binary, width=0.5, edgecolor='white')\n",
    "\n",
    "for bar, val in zip(bars, [binary_counts.get(0, 0), binary_counts.get(1, 0)]):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "             f'{val:,}\\n({val/len(df)*100:.1f}%)', ha='center', va='bottom',\n",
    "             fontsize=11, fontweight='bold')\n",
    "\n",
    "ax2.set_ylabel('Number of Reports')\n",
    "ax2.set_title('Binary Classification Target', fontsize=12, fontweight='bold')\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/01_severity_distribution.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/01_severity_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Top Reaction Terms\n",
    "# Parse all reaction terms\n",
    "all_reactions = []\n",
    "for terms in df['reaction_terms'].dropna():\n",
    "    all_reactions.extend([t.strip() for t in str(terms).split('|') if t.strip()])\n",
    "\n",
    "reaction_counts = Counter(all_reactions)\n",
    "top_reactions = pd.DataFrame(reaction_counts.most_common(20), \n",
    "                              columns=['Reaction', 'Count'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors_react = plt.cm.Blues(np.linspace(0.4, 0.9, len(top_reactions)))\n",
    "bars = ax.barh(top_reactions['Reaction'][::-1], top_reactions['Count'][::-1],\n",
    "               color=colors_react, edgecolor='white', height=0.7)\n",
    "\n",
    "for bar, val in zip(bars, top_reactions['Count'][::-1]):\n",
    "    ax.text(val + 20, bar.get_y() + bar.get_height()/2,\n",
    "            f'{val:,}', va='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Number of Reports')\n",
    "ax.set_title('Top 20 Most Frequent Adverse Event Terms (MedDRA)', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/02_top_reactions.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/02_top_reactions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Severity by Patient Demographics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Age distribution by severity\n",
    "ax1 = axes[0]\n",
    "for severity, color, label in [(0, COLORS['success'], 'Non-Severe'), \n",
    "                                (1, COLORS['danger'], 'Severe')]:\n",
    "    data = df[df['is_severe'] == severity]['age_years'].dropna()\n",
    "    ax1.hist(data, bins=30, alpha=0.6, color=color, label=label, edgecolor='white')\n",
    "\n",
    "ax1.set_xlabel('Age (Years)')\n",
    "ax1.set_ylabel('Number of Reports')\n",
    "ax1.set_title('Age Distribution by Severity', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Severity rate by sex\n",
    "ax2 = axes[1]\n",
    "sex_severity = df.groupby('sex_label')['is_severe'].mean().drop('Unknown', errors='ignore')\n",
    "bars = ax2.bar(sex_severity.index, sex_severity.values, \n",
    "               color=[COLORS['primary'], COLORS['secondary']], width=0.5)\n",
    "\n",
    "for bar, val in zip(bars, sex_severity.values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{val:.1%}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "ax2.set_ylabel('Severe Event Rate')\n",
    "ax2.set_title('Severity Rate by Sex', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "# Severity by reporter type\n",
    "ax3 = axes[2]\n",
    "reporter_severity = df.groupby('is_health_professional')['is_severe'].mean()\n",
    "labels = ['Consumer/Other', 'Health Professional']\n",
    "bars = ax3.bar(labels, reporter_severity.values,\n",
    "               color=[COLORS['accent'], COLORS['teal']], width=0.5)\n",
    "\n",
    "for bar, val in zip(bars, reporter_severity.values):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{val:.1%}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "ax3.set_ylabel('Severe Event Rate')\n",
    "ax3.set_title('Severity Rate by Reporter Type', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/03_demographics_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/03_demographics_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Number of reactions/drugs vs severity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Reactions per report by severity\n",
    "ax1 = axes[0]\n",
    "for severity, color, label in [(0, COLORS['success'], 'Non-Severe'), \n",
    "                                (1, COLORS['danger'], 'Severe')]:\n",
    "    data = df[df['is_severe'] == severity]['num_reactions']\n",
    "    data = data[data < 20]  # Filter outliers\n",
    "    ax1.hist(data, bins=20, alpha=0.6, color=color, label=label, edgecolor='white')\n",
    "\n",
    "ax1.set_xlabel('Number of Reaction Terms per Report')\n",
    "ax1.set_ylabel('Number of Reports')\n",
    "ax1.set_title('Reaction Count Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Drugs per report by severity\n",
    "ax2 = axes[1]\n",
    "for severity, color, label in [(0, COLORS['success'], 'Non-Severe'), \n",
    "                                (1, COLORS['danger'], 'Severe')]:\n",
    "    data = df[df['is_severe'] == severity]['num_drugs']\n",
    "    data = data[data < 20]  # Filter outliers\n",
    "    ax2.hist(data, bins=20, alpha=0.6, color=color, label=label, edgecolor='white')\n",
    "\n",
    "ax2.set_xlabel('Number of Drugs per Report')\n",
    "ax2.set_ylabel('Number of Reports')\n",
    "ax2.set_title('Drug Count Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_count_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/04_count_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NLP Feature Engineering\n",
    "\n",
    "We'll create text features from:\n",
    "1. **Reaction terms** (MedDRA coded terms) - TF-IDF vectorization\n",
    "2. **Drug indications** - TF-IDF vectorization\n",
    "3. **Structured features** - Patient demographics, counts, reporter type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text preprocessing\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and normalize text for NLP\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    text = str(text).upper()\n",
    "    # Remove special characters but keep spaces\n",
    "    text = re.sub(r'[^A-Z\\s]', ' ', text)\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Preprocess reaction text\n",
    "df['reaction_text_clean'] = df['reaction_text'].apply(preprocess_text)\n",
    "df['indication_text_clean'] = df['drug_indications'].apply(preprocess_text)\n",
    "\n",
    "# Combine reaction and indication text\n",
    "df['combined_text'] = df['reaction_text_clean'] + ' ' + df['indication_text_clean']\n",
    "\n",
    "print(\"üìù TEXT FEATURE EXAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nSample reaction terms:\")\n",
    "for i, text in enumerate(df['reaction_text_clean'].head(3)):\n",
    "    print(f\"   {i+1}. {text[:100]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ Text preprocessing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF features from reaction text\n",
    "print(\"üî§ Creating TF-IDF features...\")\n",
    "\n",
    "# TF-IDF for reaction terms (main text feature)\n",
    "tfidf_reactions = TfidfVectorizer(\n",
    "    max_features=500,         # Top 500 terms\n",
    "    min_df=5,                 # Appear in at least 5 documents\n",
    "    max_df=0.95,              # Not in more than 95% of documents\n",
    "    ngram_range=(1, 2),       # Unigrams and bigrams\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_reaction_tfidf = tfidf_reactions.fit_transform(df['reaction_text_clean'])\n",
    "print(f\"   Reaction TF-IDF shape: {X_reaction_tfidf.shape}\")\n",
    "\n",
    "# Get feature names for interpretation\n",
    "reaction_features = tfidf_reactions.get_feature_names_out()\n",
    "print(f\"   Sample features: {list(reaction_features[:10])}\")\n",
    "\n",
    "# TF-IDF for drug indications (secondary text feature)\n",
    "tfidf_indications = TfidfVectorizer(\n",
    "    max_features=200,\n",
    "    min_df=5,\n",
    "    max_df=0.95,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_indication_tfidf = tfidf_indications.fit_transform(df['indication_text_clean'])\n",
    "print(f\"   Indication TF-IDF shape: {X_indication_tfidf.shape}\")\n",
    "\n",
    "print(\"\\n‚úÖ TF-IDF vectorization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structured features\n",
    "print(\"üìä Creating structured features...\")\n",
    "\n",
    "# Numeric features\n",
    "df['age_years_clean'] = df['age_years'].fillna(df['age_years'].median())\n",
    "df['weight_kg_clean'] = df['weight_kg'].fillna(df['weight_kg'].median())\n",
    "df['num_reactions_clean'] = df['num_reactions'].clip(upper=20)  # Cap outliers\n",
    "df['num_drugs_clean'] = df['num_drugs'].clip(upper=20)\n",
    "\n",
    "structured_features = ['age_years_clean', 'weight_kg_clean', 'num_reactions_clean',\n",
    "                       'num_drugs_clean', 'num_suspect_drugs', 'is_health_professional']\n",
    "\n",
    "# One-hot encode sex\n",
    "sex_dummies = pd.get_dummies(df['sex'], prefix='sex')\n",
    "df = pd.concat([df, sex_dummies], axis=1)\n",
    "structured_features.extend(sex_dummies.columns.tolist())\n",
    "\n",
    "# Create structured feature matrix\n",
    "X_structured = df[structured_features].values\n",
    "\n",
    "# Scale structured features\n",
    "scaler = StandardScaler()\n",
    "X_structured_scaled = scaler.fit_transform(X_structured)\n",
    "X_structured_sparse = csr_matrix(X_structured_scaled)\n",
    "\n",
    "print(f\"   Structured features shape: {X_structured_sparse.shape}\")\n",
    "print(f\"   Features: {structured_features}\")\n",
    "\n",
    "print(\"\\n‚úÖ Structured features complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features\n",
    "print(\"üîó Combining feature matrices...\")\n",
    "\n",
    "X_combined = hstack([X_reaction_tfidf, X_indication_tfidf, X_structured_sparse])\n",
    "\n",
    "# Create feature names list for interpretation\n",
    "all_feature_names = (list(reaction_features) + \n",
    "                     list(tfidf_indications.get_feature_names_out()) + \n",
    "                     structured_features)\n",
    "\n",
    "# Target variable\n",
    "y = df['is_severe'].values\n",
    "\n",
    "print(f\"\\nüìä FINAL FEATURE MATRIX\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total samples: {X_combined.shape[0]:,}\")\n",
    "print(f\"Total features: {X_combined.shape[1]:,}\")\n",
    "print(f\"   - Reaction TF-IDF: {X_reaction_tfidf.shape[1]}\")\n",
    "print(f\"   - Indication TF-IDF: {X_indication_tfidf.shape[1]}\")\n",
    "print(f\"   - Structured: {X_structured_sparse.shape[1]}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"   Severe: {y.sum():,} ({y.mean()*100:.1f}%)\")\n",
    "print(f\"   Non-severe: {(1-y).sum():,} ({(1-y.mean())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(\"üìä TRAIN/TEST SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training samples: {X_train.shape[0]:,}\")\n",
    "print(f\"Test samples: {X_test.shape[0]:,}\")\n",
    "print(f\"Training severe rate: {y_train.mean()*100:.1f}%\")\n",
    "print(f\"Test severe rate: {y_test.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "# Note: Using class_weight='balanced' to handle class imbalance\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=RANDOM_STATE, \n",
    "        max_iter=1000,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'Naive Bayes': MultinomialNB(),  # Good baseline for text classification\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=RANDOM_STATE, \n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"ü§ñ TRAINING MODELS WITH 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüìà Training {name}...\")\n",
    "    \n",
    "    # For Naive Bayes, need non-negative data\n",
    "    if name == 'Naive Bayes':\n",
    "        # Use only TF-IDF features for NB\n",
    "        X_tr_nb = hstack([X_reaction_tfidf, X_indication_tfidf])\n",
    "        X_train_nb, X_test_nb, _, _ = train_test_split(\n",
    "            X_tr_nb, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "        )\n",
    "        X_tr, X_te = X_train_nb, X_test_nb\n",
    "    else:\n",
    "        X_tr, X_te = X_train, X_test\n",
    "    \n",
    "    # Cross-validation\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_tr, y_train, cv=cv, scoring='roc_auc')\n",
    "        print(f\"   CV AUC: {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"   CV skipped: {e}\")\n",
    "        scores = [0]\n",
    "    \n",
    "    # Fit on full training set\n",
    "    model.fit(X_tr, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_prob = model.predict_proba(X_te)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc,\n",
    "        'cv_mean': np.mean(scores),\n",
    "        'cv_std': np.std(scores)\n",
    "    }\n",
    "    \n",
    "    print(f\"   Test AUC: {roc_auc:.4f}\")\n",
    "    print(f\"   Accuracy: {results[name]['accuracy']:.4f}\")\n",
    "    print(f\"   F1 Score: {results[name]['f1']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ All models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metrics summary\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'CV AUC': [f\"{results[m]['cv_mean']:.4f} ¬± {results[m]['cv_std']:.4f}\" for m in results],\n",
    "    'Test AUC': [results[m]['auc'] for m in results],\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'Precision': [results[m]['precision'] for m in results],\n",
    "    'Recall': [results[m]['recall'] for m in results],\n",
    "    'F1 Score': [results[m]['f1'] for m in results]\n",
    "}).round(4)\n",
    "\n",
    "metrics_df = metrics_df.sort_values('Test AUC', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nüìä MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Save\n",
    "metrics_df.to_csv('model_metrics_summary.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved: model_metrics_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: ROC Curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors_models = [COLORS['primary'], COLORS['secondary'], COLORS['accent'], COLORS['purple']]\n",
    "\n",
    "for (name, res), color in zip(results.items(), colors_models):\n",
    "    ax.plot(res['fpr'], res['tpr'], color=color, lw=2,\n",
    "            label=f\"{name} (AUC = {res['auc']:.3f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=1.5, alpha=0.7, label='Random Classifier')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves: Adverse Event Severity Classification', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/05_roc_curves.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/05_roc_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6: Confusion Matrix (Best Model)\n",
    "best_model_name = metrics_df.iloc[0]['Model']\n",
    "best_results = results[best_model_name]\n",
    "\n",
    "cm = confusion_matrix(y_test, best_results['y_pred'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Non-Severe', 'Severe'],\n",
    "            yticklabels=['Non-Severe', 'Severe'],\n",
    "            annot_kws={'size': 16}, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_title(f'Confusion Matrix: {best_model_name}\\n(AUC: {best_results[\"auc\"]:.3f})',\n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/06_confusion_matrix.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/06_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7: Top Predictive Features (Logistic Regression coefficients)\n",
    "lr_model = results['Logistic Regression']['model']\n",
    "coefficients = lr_model.coef_[0]\n",
    "\n",
    "# Get top features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Top positive (predict severe) and negative (predict non-severe)\n",
    "top_positive = feature_importance.nlargest(15, 'Coefficient')\n",
    "top_negative = feature_importance.nsmallest(15, 'Coefficient')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Predictors of Severe\n",
    "ax1 = axes[0]\n",
    "colors_pos = plt.cm.Reds(np.linspace(0.4, 0.9, len(top_positive)))\n",
    "bars = ax1.barh(top_positive['Feature'], top_positive['Coefficient'],\n",
    "                color=colors_pos, edgecolor='white')\n",
    "ax1.set_xlabel('Coefficient (Log-Odds)', fontsize=11)\n",
    "ax1.set_title('Top Predictors of SEVERE Outcome', fontsize=12, fontweight='bold')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Predictors of Non-Severe\n",
    "ax2 = axes[1]\n",
    "colors_neg = plt.cm.Greens(np.linspace(0.4, 0.9, len(top_negative)))\n",
    "bars = ax2.barh(top_negative['Feature'], top_negative['Coefficient'],\n",
    "                color=colors_neg, edgecolor='white')\n",
    "ax2.set_xlabel('Coefficient (Log-Odds)', fontsize=11)\n",
    "ax2.set_title('Top Predictors of NON-SEVERE Outcome', fontsize=12, fontweight='bold')\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.suptitle('Logistic Regression Feature Importance', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/07_feature_coefficients.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/07_feature_coefficients.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SHAP Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis using Logistic Regression (linear model)\n",
    "print(\"üîç Computing SHAP values...\")\n",
    "print(\"   (Using a sample for computational efficiency)\\n\")\n",
    "\n",
    "# Sample for SHAP (computational efficiency)\n",
    "sample_size = min(1000, X_test.shape[0])\n",
    "sample_idx = np.random.choice(X_test.shape[0], sample_size, replace=False)\n",
    "X_test_sample = X_test[sample_idx].toarray()  # Convert to dense for SHAP\n",
    "\n",
    "# Use Linear explainer for Logistic Regression\n",
    "lr_model = results['Logistic Regression']['model']\n",
    "explainer = shap.LinearExplainer(lr_model, X_train.toarray()[:1000], feature_names=all_feature_names)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "print(\"‚úÖ SHAP values computed!\")\n",
    "print(f\"   Shape: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8: SHAP Summary Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    X_test_sample,\n",
    "    feature_names=all_feature_names,\n",
    "    plot_type=\"dot\",\n",
    "    show=False,\n",
    "    max_display=20\n",
    ")\n",
    "\n",
    "plt.title('SHAP Feature Impact on Severity Prediction', fontsize=14, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/08_shap_summary.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/08_shap_summary.png\")\n",
    "\n",
    "print(\"\\nüìä SHAP INTERPRETATION:\")\n",
    "print(\"   ‚Ä¢ Red points = high feature values\")\n",
    "print(\"   ‚Ä¢ Blue points = low feature values\")\n",
    "print(\"   ‚Ä¢ Right of center = increases severity prediction\")\n",
    "print(\"   ‚Ä¢ Left of center = decreases severity prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9: SHAP Bar Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    X_test_sample,\n",
    "    feature_names=all_feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    show=False,\n",
    "    max_display=20\n",
    ")\n",
    "\n",
    "plt.title('Mean Absolute SHAP Value (Feature Importance)', fontsize=14, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/09_shap_importance.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"‚úÖ Saved: figures/09_shap_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate predictions on sample cases\n",
    "print(\"üîÆ SAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get best model\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "# Show some examples\n",
    "test_indices = np.random.choice(len(y_test), 5, replace=False)\n",
    "\n",
    "for i, idx in enumerate(test_indices):\n",
    "    actual = y_test[idx]\n",
    "    if best_model_name == 'Naive Bayes':\n",
    "        pred_prob = results[best_model_name]['y_prob'][idx]\n",
    "    else:\n",
    "        pred_prob = best_model.predict_proba(X_test[idx])[0, 1]\n",
    "    \n",
    "    # Get original data\n",
    "    original_idx = df.index[int(len(df) * 0.8) + idx]  # Approximate test index\n",
    "    \n",
    "    print(f\"\\nCase {i+1}:\")\n",
    "    print(f\"   Predicted Severity Probability: {pred_prob:.2%}\")\n",
    "    print(f\"   Prediction: {'SEVERE' if pred_prob > 0.5 else 'Non-Severe'}\")\n",
    "    print(f\"   Actual: {'SEVERE' if actual == 1 else 'Non-Severe'}\")\n",
    "    print(f\"   Correct: {'‚úÖ' if (pred_prob > 0.5) == actual else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"                    üìä FINAL PROJECT SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìà Dataset: {len(df):,} adverse event reports from FDA FAERS\")\n",
    "print(f\"   - Severe: {df['is_severe'].sum():,} ({df['is_severe'].mean()*100:.1f}%)\")\n",
    "print(f\"   - Non-severe: {(1-df['is_severe']).sum():,} ({(1-df['is_severe'].mean())*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Test AUC: {best_results['auc']:.4f}\")\n",
    "print(f\"   Accuracy: {best_results['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {best_results['precision']:.4f}\")\n",
    "print(f\"   Recall: {best_results['recall']:.4f}\")\n",
    "print(f\"   F1 Score: {best_results['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nüîë KEY FINDINGS:\")\n",
    "print(\"\\n   1. NLP FEATURES ARE PREDICTIVE:\")\n",
    "print(\"      - MedDRA reaction terms carry strong signal for severity\")\n",
    "print(\"      - Specific terms like 'death', 'cardiac', 'respiratory' indicate severity\")\n",
    "\n",
    "print(\"\\n   2. CLINICAL PATTERNS EMERGE:\")\n",
    "print(\"      - More drugs/reactions per report = higher severity risk\")\n",
    "print(\"      - Health professional reporters submit more severe cases\")\n",
    "print(\"      - Age correlates with certain severity patterns\")\n",
    "\n",
    "print(\"\\n   3. MODEL INTERPRETABILITY:\")\n",
    "print(\"      - SHAP values identify specific terms driving predictions\")\n",
    "print(\"      - Logistic regression coefficients provide clear feature weights\")\n",
    "print(\"      - Results align with clinical expectations\")\n",
    "\n",
    "print(\"\\nüìÅ Outputs generated:\")\n",
    "print(\"   - 9 figures in figures/ directory\")\n",
    "print(\"   - model_metrics_summary.csv\")\n",
    "print(\"   - data/faers_adverse_events.csv (cached API data)\")\n",
    "\n",
    "print(\"\\nüí° BUSINESS APPLICATIONS:\")\n",
    "print(\"   - Automated triage of safety reports\")\n",
    "print(\"   - Priority queue for medical review\")\n",
    "print(\"   - Support for 15-day expedited reporting compliance\")\n",
    "print(\"   - Signal detection for pharmacovigilance\")\n",
    "print(\"   - Risk scoring for drug portfolios\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"      Project by Jason Finkle | github.com/jfinkle00\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
